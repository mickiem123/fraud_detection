{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17698283",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.baseline.data_ingestion import DataIngestorFactory, DataIngestorConfig\n",
    "from src.baseline.features_engineering import PreprocessorPipeline\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pandas\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9ed4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thuhi\\workspace\\fraud_detection\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.chdir(rf\"c:\\Users\\thuhi\\workspace\\fraud_detection\")\n",
    "print(os.getcwd())\n",
    "\n",
    "factory = DataIngestorFactory()\n",
    "ingestor = factory.create_ingestor(\"duration_pkl\")\n",
    "train_df, validation_df = ingestor.ingest(\n",
    "    dir_path=rf\"C:\\Users\\thuhi\\workspace\\fraud_detection\\data\\transformed_data\",\n",
    "    start_train_date=\"2018-07-25\",\n",
    "    train_duration=7,\n",
    "    test_duration=7,\n",
    "    delay=7\n",
    ")\n",
    "\n",
    "config = DataIngestorConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10cdccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialFraudDetectionDataset(Dataset):\n",
    "    def __init__(self,df:pd.DataFrame,seq_len =7):\n",
    "        self.config = DataIngestorConfig()\n",
    "        self.seq_len = seq_len\n",
    "        self.num_samples = len(df)\n",
    "        self.df = df.copy()\n",
    "        self.df.sort_values(\"TX_DATETIME\",inplace=True)\n",
    "        self.df.reset_index(drop=True,inplace=True)\n",
    "        self.df[\"tmp_idx\"] = np.arange(len(self.df))\n",
    "        for i in range( seq_len+1):\n",
    "            self.df[f\"tx{i}\"] = self.df.groupby(\"CUSTOMER_ID\")[\"tmp_idx\"].shift(seq_len-i-1)\n",
    "        self.df = self.df.sort_values([\"CUSTOMER_ID\", \"TX_DATETIME\"]).fillna(self.num_samples)\n",
    "        # Create a -1 index row with all zero values (matching df columns)\n",
    "        zero_row = pd.DataFrame({col: [0] for col in df.columns}, index=[self.num_samples ])\n",
    "        self.df = pd.concat([zero_row, self.df])\n",
    "        # Precompute features and targets as tensors\n",
    "        self.df.sort_index(inplace=True)\n",
    "        self.features = torch.tensor(self.df[self.config.input_features].values, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(self.df[self.config.output_feature].values, dtype=torch.int8)\n",
    "        # Precompute sequence indices\n",
    "        self.tx_indices = torch.tensor(self.df[[f\"tx{i}\" for i in range(1, seq_len + 1)]].values, dtype=torch.long)\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    def __getitem__(self, index):\n",
    "        # Use precomputed tensors with gathered indices\n",
    "        #st = time.time()\n",
    "        tx_ids = self.tx_indices[index]\n",
    "        # Gather features for the sequence\n",
    "        features = self.features[tx_ids]\n",
    "        target = self.targets[index]\n",
    "        #logger.info(f\"time{time.time()-st}\")\n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba160464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "         [1.3022e-05, 1.3523e-01, 6.8467e-01, 8.6757e-03, 5.6426e-05, 0.0000e+00],\n",
       "         [3.3949e-02, 1.3523e-01, 3.6224e-01, 1.5241e-02, 4.6452e-02, 0.0000e+00]]),\n",
       " tensor(0, dtype=torch.int8))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train_preprocessed = PreprocessorPipeline(train_df,add_method=[\"scale\"]).process()\n",
    "data = SequentialFraudDetectionDataset(train_preprocessed)\n",
    "data[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8320555c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "501b9336",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudSequenceDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, x,y,customer_ids, dates, seq_len, padding_mode = 'zeros', output=True):\n",
    "        'Initialization'\n",
    "        \n",
    "        # x,y,customer_ids, and dates must have the same length\n",
    "        \n",
    "        # storing the features x in self.features and adding the \"padding\" transaction at the end\n",
    "        if padding_mode == \"mean\":\n",
    "            self.features = torch.vstack([x, x.mean(axis=0)])\n",
    "        elif padding_mode == \"zeros\":\n",
    "            self.features = torch.vstack([x, torch.zeros(x[0,:].shape)])            \n",
    "        else:\n",
    "            raise ValueError('padding_mode must be \"mean\" or \"zeros\"')\n",
    "        self.y = y\n",
    "        self.customer_ids = customer_ids\n",
    "        self.dates = dates\n",
    "        self.seq_len = seq_len\n",
    "        self.output = output\n",
    "        \n",
    "        #===== computing sequences ids =====  \n",
    "        \n",
    "        \n",
    "        df_ids_dates = pd.DataFrame({'CUSTOMER_ID':customer_ids,\n",
    "        'TX_DATETIME':dates})\n",
    "        \n",
    "        df_ids_dates[\"tmp_index\"]  = np.arange(len(df_ids_dates))\n",
    "        df_groupby_customer_id = df_ids_dates.groupby(\"CUSTOMER_ID\")\n",
    "        sequence_indices = pd.DataFrame(\n",
    "            {\n",
    "                \"tx_{}\".format(n): df_groupby_customer_id[\"tmp_index\"].shift(seq_len - n - 1)\n",
    "                for n in range(seq_len)\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        #replaces -1 (padding) with the index of the padding transaction (last index of self.features)\n",
    "        self.sequences_ids = sequence_indices.fillna(len(self.features) - 1).values.astype(int)              \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        # not len(self.features) because of the added padding transaction\n",
    "        return len(self.customer_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample index\n",
    "        \n",
    "        tx_ids = self.sequences_ids[index]\n",
    "        \n",
    "        if self.output:\n",
    "            #transposing because the CNN considers the channel dimension before the sequence dimension\n",
    "            return self.features[tx_ids,:].transpose(0,1), self.y[index]\n",
    "        else:\n",
    "            return self.features[tx_ids,:].transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecc15700",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(train_df[config.input_features_transformed].values)\n",
    "y_train = torch.tensor(train_df[config.output_feature].values)\n",
    "\n",
    "training_set = FraudSequenceDataset(x_train, y_train,\n",
    "                                    train_df['CUSTOMER_ID'].values,\n",
    "                                    train_df['TX_DATETIME'].values,\n",
    "                                    seq_len=7,\n",
    "                                    padding_mode=\"zeros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed31b90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([76792,  8365, 11818, 11842, 18540, 27439, 34216])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.sequences_ids[34216]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7b417e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = train_df['TX_DATETIME'].values\n",
    "customer_ids = train_df['CUSTOMER_ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b922303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_sort = np.argsort(dates)\n",
    "sorted_dates = dates[indices_sort]\n",
    "sorted_ids = customer_ids[indices_sort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef678b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  4,  5,  6,  7,  8,  9, 10], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_customer_ids = np.unique(sorted_ids)\n",
    "unique_customer_ids[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bf5d722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8365, 11818, 11842, 18540, 27439, 34216, 41017, 46994, 50788,\n",
       "       58551, 61935, 72196, 73411], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "current_customer_id = unique_customer_ids[idx]\n",
    "customer_mask = sorted_ids == current_customer_id\n",
    "# this is the full sequence of transaction indices (after sort) for customer 0\n",
    "customer_full_seq = np.where(customer_mask)[0]\n",
    "# this is the full sequence of transaction indices (before sort) for customer 0\n",
    "customer_full_seq_original_indices = indices_sort[customer_full_seq]\n",
    "customer_full_seq_original_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "211fa92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   -1,    -1,    -1,    -1,    -1,    -1,  8365],\n",
       "       [   -1,    -1,    -1,    -1,    -1,  8365, 11818],\n",
       "       [   -1,    -1,    -1,    -1,  8365, 11818, 11842],\n",
       "       [   -1,    -1,    -1,  8365, 11818, 11842, 18540],\n",
       "       [   -1,    -1,  8365, 11818, 11842, 18540, 27439],\n",
       "       [   -1,  8365, 11818, 11842, 18540, 27439, 34216],\n",
       "       [ 8365, 11818, 11842, 18540, 27439, 34216, 41017],\n",
       "       [11818, 11842, 18540, 27439, 34216, 41017, 46994],\n",
       "       [11842, 18540, 27439, 34216, 41017, 46994, 50788],\n",
       "       [18540, 27439, 34216, 41017, 46994, 50788, 58551],\n",
       "       [27439, 34216, 41017, 46994, 50788, 58551, 61935],\n",
       "       [34216, 41017, 46994, 50788, 58551, 61935, 72196],\n",
       "       [41017, 46994, 50788, 58551, 61935, 72196, 73411]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rolling_window(array, window):\n",
    "    a = np.concatenate([np.ones((window-1,))*-1,array])\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides).astype(int)\n",
    "customer_all_seqs = rolling_window(customer_full_seq_original_indices,7)\n",
    "customer_all_seqs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud_detection_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
